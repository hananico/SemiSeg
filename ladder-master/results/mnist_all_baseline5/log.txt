Logging into results/mnist_all_baseline5/log.txt
== COMMAND LINE ==
run.py train --encoder-layers 1000-500-250-250-250-10 --decoder-spec 0-0-0-0-0-0-0 --denoising-cost-x 0,0,0,0,0,0,0 --labeled-samples 60000 --unlabeled-samples 60000 --f-local-noise-std 0.5 --seed 1 -- mnist_all_baseline
== PARAMETERS ==
 zestbn              : bugfix               
 dseed               : 1                    
 top_c               : 1                    
 super_noise_std     : 0.3                  
 batch_size          : 100                  
 dataset             : mnist                
 valid_set_size      : 10000                
 num_epochs          : 150                  
 whiten_zca          : 0                    
 unlabeled_samples   : 60000                
 decoder_spec        : ('0', '0', '0', '0', '0', '0', '0') 
 valid_batch_size    : 100                  
 denoising_cost_x    : (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0) 
 f_local_noise_std   : (0.5,)               
 cmd                 : train                
 act                 : relu                 
 lrate_decay         : 0.67                 
 seed                : 1                    
 lr                  : 0.002                
 save_to             : mnist_all_baseline   
 save_dir            : results/mnist_all_baseline5 
 commit              :                      
 contrast_norm       : 0                    
 encoder_layers      : ('1000', '500', '250', '250', '250', '10') 
 labeled_samples     : 60000                
Using 0 examples for validation
Encoder: clean, labeled
  0: noise 0
  f1: fc, relu, BN, noise 0.00, params 1000, dim (1, 28, 28) -> (1000,)
  f2: fc, relu, BN, noise 0.00, params 500, dim (1000,) -> (500,)
  f3: fc, relu, BN, noise 0.00, params 250, dim (500,) -> (250,)
  f4: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)
  f5: fc, relu, BN, noise 0.00, params 250, dim (250,) -> (250,)
  f6: fc, softmax, BN, noise 0.00, params 10, dim (250,) -> (10,)
Encoder: corr, labeled
  0: noise 0.3
  f1: fc, relu, BN, noise 0.50, params 1000, dim (1, 28, 28) -> (1000,)
  f2: fc, relu, BN, noise 0.50, params 500, dim (1000,) -> (500,)
  f3: fc, relu, BN, noise 0.50, params 250, dim (500,) -> (250,)
  f4: fc, relu, BN, noise 0.50, params 250, dim (250,) -> (250,)
  f5: fc, relu, BN, noise 0.50, params 250, dim (250,) -> (250,)
  f6: fc, softmax, BN, noise 0.50, params 10, dim (250,) -> (10,)
Decoder: z_corr -> z_est
  g6:          0, , dim None -> (10,)
  g5:          0, , dim (10,) -> (250,)
  g4:          0, , dim (250,) -> (250,)
  g3:          0, , dim (250,) -> (250,)
  g2:          0, , dim (250,) -> (500,)
  g1:          0, , dim (500,) -> (1000,)
  g0:          0, , dim (1000,) -> (1, 28, 28)
Found the following parameters: [f_6_c, f_6_b, f_5_b, f_4_b, f_3_b, f_2_b, f_1_b, f_1_W, f_2_W, f_3_W, f_4_W, f_5_W, f_6_W]
Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean, f_6_bn_mean_clean, f_6_bn_var_clean
Batch norm parameters: f_1_bn_mean_clean, f_1_bn_var_clean, f_2_bn_mean_clean, f_2_bn_var_clean, f_3_bn_mean_clean, f_3_bn_var_clean, f_4_bn_mean_clean, f_4_bn_var_clean, f_5_bn_mean_clean, f_5_bn_var_clean, f_6_bn_mean_clean, f_6_bn_var_clean
e 0, i 0:V_C_class nan, V_E nan
e 1, i 600:V_C_class nan, V_E nan, T_C_class 0.574
Iter 1, lr 0.002000
e 2, i 1200:V_C_class nan, V_E nan, T_C_class 0.358
Iter 2, lr 0.002000
e 3, i 1800:V_C_class nan, V_E nan, T_C_class 0.303
Iter 3, lr 0.002000
e 4, i 2400:V_C_class nan, V_E nan, T_C_class 0.269
Iter 4, lr 0.002000
e 5, i 3000:V_C_class nan, V_E nan, T_C_class 0.25
Iter 5, lr 0.002000
e 6, i 3600:V_C_class nan, V_E nan, T_C_class 0.234
Iter 6, lr 0.002000
e 7, i 4200:V_C_class nan, V_E nan, T_C_class 0.22
Iter 7, lr 0.002000
e 8, i 4800:V_C_class nan, V_E nan, T_C_class 0.214
Iter 8, lr 0.002000
e 9, i 5400:V_C_class nan, V_E nan, T_C_class 0.204
Iter 9, lr 0.002000
e 10, i 6000:V_C_class nan, V_E nan, T_C_class 0.194
Iter 10, lr 0.002000
e 11, i 6600:V_C_class nan, V_E nan, T_C_class 0.188
Iter 11, lr 0.002000
e 12, i 7200:V_C_class nan, V_E nan, T_C_class 0.185
Iter 12, lr 0.002000
e 13, i 7800:V_C_class nan, V_E nan, T_C_class 0.18
Iter 13, lr 0.002000
e 14, i 8400:V_C_class nan, V_E nan, T_C_class 0.17
Iter 14, lr 0.002000
e 15, i 9000:V_C_class nan, V_E nan, T_C_class 0.169
Iter 15, lr 0.002000
Saving to results/mnist_all_baseline5/trained_params
e 15, i 9135:
